#!/usr/bin/env ruby

# Requirements
require "tty-prompt"
require "tty-spinner"
require "yaml"
require "date"

require_relative "../lib/config"
require_relative "../lib/metrics"
require_relative "../lib/report"
require_relative "../lib/statistics"
require_relative "../lib/xy"

ARGS={}
ARGV.each do |arg|
  case arg
    when '-h','--help', '-help', 'help' then ARGS[:help] = true
    else
      ARGS[:help] = true
      ARGS[:unknown] = true
    end
end

if ARGS[:help]
  if ARGS[:unknown]
    puts "Unrecognised options provided: #{ARGV}"
    puts
  end
  puts "Usage:"
  puts "   Run this command without arguments to interactively document your experience"
  puts
  puts "-h, --help, help    Show this help page"
  puts
  exit
end

issues = {}
statuses = {}

report = Report.new

# Create prompt
prompt = TTY::Prompt.new(active_color: :blue, interrupt: :exit)

#
# Stage 0: Log that someone has actually used this
#

accesslogfile = "#{Config.accesslogsdir}/.user-access-#{report.log['meta']['username']}"
File.open(accesslogfile, 'a+') do |f|
  f.puts("#{report.log['meta']['username']} ran the command at #{DateTime.parse(report.log['meta']['reported_at']).strftime("%Y-%m-%d %H:%M:%S")}")
end

#
# Stage 1: Traffic Light Response Rating
#

happy = prompt.select("How would you rate your experience on your HPC environment today?", Config.traffic_lights.invert)
report.log['meta']['rating'] = happy

ratingfile = "#{Config.ratingsdir}/#{report.ratingfilename}"
File.open(ratingfile, 'a+') do |f|
  f.puts(report.log['meta']['rating'])
end

if happy == 2
  puts "Thank you for time! Your response has been recorded"
  exit
end

#
# Stag 2: Display Status Updates
#

# Status reports
statuses = all_statuses
puts "Status Reports:"
if statuses.count > 0
  puts statuses
else
  puts "- No statuses to report"
end

# Cumulative ratings
recent_ratings = all_ratings

puts
puts "Ratings (Past Hour)"
puts XY.bar(recent_ratings)
puts

#
# Stage 3: Selecting Issue
#

# Check with user
if ! Config.always_report 
  yes = prompt.yes?('Would you like to report an issue?', default: false)
  if ! yes
    puts "Thank you for time! Your response has been recorded"
    exit
  end
end

# Identify issues by directory name so we can run scripts and things from in there
issuedirs = Dir.entries(Config.issuesdir).select{|dir| !(dir == '.' || dir == '..' || dir == 'general')}
# Create a map of all the issue directories and their metadata+questions
issuedirs.each do |issue|
  issuedir = "#{Config.issuesdir}/#{issue}"
  issues[issue] = YAML.load_file("#{issuedir}/metadata.yaml")
  if File.file? "#{issuedir}/questions.yaml"
    issues[issue]['questions'] = YAML.load_file("#{issuedir}/questions.yaml")
  end
end
my_issue_dir = prompt.select("What issue would you like to report?") do |menu|
  issues.each.map {|dir,data| menu.choice "#{data['title']} (#{data['desc']})", dir}
end

my_issue = issues[my_issue_dir]
report.log['meta']['issue_id'] = my_issue_dir

# Ask additional questions
diag_vars = {}
if my_issue.key?('questions') then
  my_issue['questions'].each do |question|
    case question['type']
    when "boolean"
      answer = prompt.yes?(question['question'])
    when "list"
      answer = prompt.select(question['question'], question['options'])
    when "text"
      answer = prompt.ask(question['question'])
    when "number"
      answer = prompt.ask(question['question']) do |q|
        q.validate(/^[0-9]*$/, "Answer must be a number or empty")
      end
    end
    diag_vars[question['var']] = answer
  end
end

report.log['diagnostics']['issue']['answers'] = diag_vars

#
# Stage 4: Check metrics
#
spinner = TTY::Spinner.new(":spinner Checking metrics ...", format: :bouncing_ball)
spinner.auto_spin

## Run general metrics
general_metrics_file = "#{Config.issuesdir}/general/metrics.yaml"
metrics_out = {}

if File.file?(general_metrics_file)
  metrics_out.merge!(check_metrics(general_metrics_file))
end

## Run issue-specific metrics
issue_metrics_file = "#{Config.issuesdir}/#{my_issue_dir}/metrics.yaml"

if File.file?(issue_metrics_file)
  diag_vars.each do |key, val|
    ENV[key] = val
  end
  metrics_out.merge!(check_metrics(issue_metrics_file))
end

report.log['metrics'] = metrics_out

## Wait for grace period
sleep(Config.metric_grace_period)

## Tell user pass/fail of metrics
failcount, failmetrics = failed_metrics(metrics_out)
if failcount == 0
  spinner.success("All #{metrics_out.count} Checks Passed")
else
  spinner.error("Warning with #{failcount}/#{metrics_out.count} Checks")
  report_metrics_detail(metrics_out)
end

#
# Stage 5: Run diagnostics
#
spinner = TTY::Spinner.new(":spinner Running diagnostics ...", format: :bouncing_ball)
spinner.auto_spin

general_scripts = Dir.glob("#{Config.issuesdir}/general/*.bash")
## General scripts
general_script_outputs = []
general_scripts.each do |script|
  out = `bash #{script} 2>&1`
  # Ensure that YAML output is multiline by replacing tabs with 4 spaces (https://yaml.org/faq.html)
  out.gsub! /\t/, '    '
  report.log['diagnostics']['general'][File.basename(script)] = {
    'script_md5sum'=> nil,
    'output'=> out
  }
  general_script_outputs.append(out)
end

## Issue specific
issue_script = "#{Config.issuesdir}/#{my_issue_dir}/diagnostics.bash"

if File.file?(issue_script)
  diag_vars.each do |key, val|
    ENV[key] = val
  end

  issue_script_out = `bash #{issue_script} 2>&1`
  # Ensure that YAML output is multiline by replacing tabs with 4 spaces (https://yaml.org/faq.html)
  issue_script_out.gsub! /\t/, '    '
  report.log['diagnostics']['issue']['output'] = issue_script_out
end

## Wait for grace period
sleep(Config.diagnostic_grace_period)
spinner.success("Done!")

# Show diagnostics to user
if ! Config.hide_diagnostics
  view = prompt.yes?("Would you like to view diagnostics?", default: false)
  if view
    IO.popen("less", "w") { |f| f.puts report.outputs }
  end
end

#
# Stage 6: Compare to previous
#
if ! Config.hide_compare
  # TODO: Identify latest by 'issue_at' time
  prev_report_from_user = Dir.glob("#{Config.reportsdir}/.user-report-#{my_issue_dir}-#{report.log['meta']['username']}*.log").last

  if prev_report_from_user && File.file?(prev_report_from_user)
    prev_report = Report.new(prev_report_from_user)
    prev_datetime = prev_report.log['meta']['issue_at']
    compare = prompt.yes?("Would you like to compare diagnostics to your previous report at #{DateTime.parse(prev_datetime).strftime("%Y-%m-%d %H:%M:%S")}?", default: false)
    if compare
      current = "# Current Diagnostics: #{DateTime.parse(report.log['meta']['issue_at']).strftime("%Y-%m-%d %H:%M:%S")}\n#{report.outputs}"
      previous = "# Previous Diagnostics: #{DateTime.parse(prev_datetime).strftime("%Y-%m-%d %H:%M:%S")}\n#{prev_report.outputs}"
      diff_to_prev = `diff -y --width=#{`tput cols`.to_i} <(echo -e '#{current}') <(echo -e '#{previous}')`
      IO.popen("less", "w") { |f| f.puts diff_to_prev }
    end
  end
end

#
# Stage 7: Logging diagnostics
# 
logfile = "#{Config.reportsdir}/#{report.reportfilename}"
if ! Config.always_send
  yesconfirm = false
else
  yesconfirm = true
  yesreport = true
end
until yesconfirm
  yesreport = prompt.yes?("Would you like to send diagnostics report for '#{my_issue['title']}' to admin?", default: false)
  yesconfirm = prompt.yes?("  Are you sure?", default: false)
end

if yesreport
  File.open(logfile, 'a+') do |f|
    f.puts(report.log.to_yaml(:options => {:line_width => -1, :indentation => 4}))
  end
  puts "Log reported, thank you for your time"
else
  puts "Not reporting, thank you for your time"
  exit
end
